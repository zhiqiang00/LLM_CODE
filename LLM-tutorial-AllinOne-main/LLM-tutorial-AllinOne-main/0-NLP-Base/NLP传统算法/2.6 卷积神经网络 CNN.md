**2.6 卷积神经网络 CNN**

<font style="color:#3370FF;">1. </font>**背景介绍**

卷积神经网络在目标检测和计算机视觉、自然语言处理、语音识别和语义分析等领域成效卓然，因此也促进了人工智能的发展。深度学习是包含多级非线性变换的层级机器学习方法，深层神经网络是目前的主要形式，其神经元间的连接模式受启发于动物视觉皮层组织，而卷积神经网络则是其中一种经典而广泛应用的网络结构。卷积神经网络的局部连接、权值共享及池化操作等特性使之可以有效地降低网络的复杂度，减少训练参数的数目，使模型对平移、扭曲、缩放具有一定程度的不变性，并具有强鲁棒性和容错能力，且也易于训练和优化网络结构。因此它在各种信号和信息处理任务中的性能优于标准的全连接神经网络。

<font style="color:#3370FF;">2. </font>**CNN的基本结构和方法**

**2.1 卷积层 **

卷积层（convolutional layer）由多个特征面（Feature Map）组成，每个特征面由多个神经元组成，它的每一个神经元通过卷积核与上一层特征面的局部区域相连。卷积核是一个权值矩阵（如对于二维而言可为3*3或5*5矩阵）[1-2]。CNN的卷积层通过卷积操作提取输入的不同特征，第一层卷积层提取低级特征如边缘、线条、角落，更高层的卷积层提取更高级的特征。

**2.2 池化层 **

池化层（pooling layer，也称为取样层）紧跟在卷积层之后，同样由多个特征面组成，它的每一个特征面唯一对应于其上一层的一个特征面，不会改变特征面的个数。池化层旨在通过降低特征面的分辨率来获得具有空间不变性的特征[3]。池化层起到二次提取特征的作用，它的每个神经元对局部接受域进行池化操作。常用的池化方法有最大池化（max-pooling）即取局部接受域中值最大的点、均值池化（mean pooling）即对局部接受域中的所有值求均值、随机池化（stachastic pooling） [4-5]。在通常所采用的池化方法中，取样层的同一个特征面不同神经元与上一层的局部接受域不重叠，然而也可以采用重叠池化（overlapping pooling）的方法。所谓重叠池化方法就是相邻的池化窗口间有重叠区域。

**2.3 全连接层 **

在CNN结构中，经多个卷积层和取样层后，连接着1个或1个以上的全连接层。与MLP类似，全连接层中的每个神经元与其前一层的所有神经元进行全连接。全连接层可以整合卷积层或者取样层中具有类别区分性的局部信息[6]。为了提升CNN网络性能，全连接层每个神经元的激励函数一般采用ReLU函数[7]。最后一层全连接层的输出值被传递给一个输出层，可以采用softmax逻辑回归（softmax regression）进行分类，该层也可称为softmax层（softmax layer）。

**2.4 特征面 **

特征面数目作为CNN 的一个重要参数，它通常是根据实际应用进行设置的，如果特征面个数过少，可能会使一些有利于网络学习的特征被忽略掉，从而不利于网络的学习；但是如果特征面个数过多，可训练参数个数及网络训练时间也会增加，这同样不利于学习网络模型。

**2.5 激活函数 **

常用激活函数有: ReLU、 Leakly ReLU、 Parametric ReLU、 Randomized ReLU、ELU 等。

**2.6 损失函数 **

损失函数的选择在卷积神经网络中起重要作 用, 代表性的损失函数有: 平方误差损失、互熵损失 (Cross entropy loss)、Hinge 损失等。

<font style="color:#3370FF;">3. </font>**卷积神经网络的优点**

卷积神经网络以其权值共享的特殊结构在图像理解领域中有着独特的优越性, 通过权值共享降低了网络的复杂性.总之, 卷积神经网络相比于一般神经网络在图像理解中有其特殊的优点:

网络结构能较好适应图像的结构; 

 同时进行特征提取和分类, 使得特征提取有助于特征分类; 

权值共享可以减少网络的训练参数,使得神经网络结构变得更简单、适应性更强。

<font style="color:#3370FF;">4. </font>**手写数字识别**

![](https://cdn.nlark.com/yuque/0/2024/png/1805392/1729130257381-6c019b62-8961-48bd-850b-b8f696f656e9.png)

                                           图1： [<font style="color:#3370FF;">手写数字识别</font>](https://www.bilibili.com/video/BV1zF411V7xu/?spm_id_from=333.337.search-card.all.click&vd_source=49d7dc394125d1aa584fca04e78a909f)

<font style="color:#8F959E;"> </font>以上过程就是识别手写数字的全部过程，整个过程需要在如下几层进行运算：

输入层：输入图像等信息

卷积层：用来提取图像的底层特征

池化层：防止过拟合，将数据维度减小

全连接层：汇总卷积层和池化层得到的图像的底层特征和信息

输出层：根据全连接层的信息得到概率最大的结果

**代码如下：**

| <font style="color:rgb(100, 106, 115);">Python</font>import matplotlib.pyplot as plt   import torch   from torchvision.datasets import MNIST   from torchvision import transforms   from torch.utils.data import DataLoader   from torch import nn   import os   from PIL import Image   import numpy as np      # 预处理：将两个步骤整合在一起   transform = transforms.Compose({       transforms.ToTensor(), # 转为Tensor，范围改为0-1       transforms.Normalize((0.1307,),(0.3081)) # 数据归一化，即均值为0，标准差为1   })      # 训练数据集   train_data = MNIST(root='./data',train=True,download=False,transform=transforms.ToTensor())   train_loader = DataLoader(train_data,shuffle=True,batch_size=64)      # 测试数据集   test_data = MNIST(root='./data',train=False,download=False,transform=transforms.ToTensor())   test_loader = DataLoader(test_data,shuffle=False,batch_size=64)      # 模型   class Model(nn.Module):       def __init__(self):           super(Model,self).__init__()           self.linear1 = nn.Linear(784,256)           self.linear2 = nn.Linear(256,64)           self.linear3 = nn.Linear(64,10) # 10个手写数字对应的10个输出          def forward(self,x):           x = x.view(-1,784) # 变形           x = torch.relu(self.linear1(x))           x = torch.relu(self.linear2(x))           x = torch.relu(self.linear3(x))           return x      # CrossEntropyLoss   model = Model()   criterion = nn.CrossEntropyLoss() # 交叉熵损失，相当于Softmax+Log+NllLoss   optimizer = torch.optim.SGD(model.parameters(),0.8) # 第一个参数是初始化参数值，第二个参数是学习率      # 模型训练   def train():       for index,data in enumerate(train_loader):           input,target = data # input为输入数据，target为标签           optimizer.zero_grad() # 梯度清零           y_predict = model(input) # 模型预测           loss = criterion(y_predict,target) # 计算损失           loss.backward() # 反向传播           optimizer.step() # 更新参数           if index % 100 == 0: # 每一百次保存一次模型，打印损失               torch.save(model.state_dict(),"./model/model.pkl") # 保存模型               torch.save(optimizer.state_dict(),"./model/optimizer.pkl")               print("损失值为：%.2f" % loss.item())      # 加载模型   if os.path.exists('./model/model.pkl'):       model.load_state_dict(torch.load("./model/model.pkl")) # 加载保存模型的参数      # 模型测试   def test():       correct = 0 # 正确预测的个数       total = 0 # 总数       with torch.no_grad(): # 测试不用计算梯度           for data in test_loader:               input,target = data               output=model(input) # output输出10个预测取值，其中最大的即为预测的数               probability,predict=torch.max(output.data,dim=1) # 返回一个元组，第一个为最大概率值，第二个为最大值的下标               total += target.size(0) # target是形状为(batch_size,1)的矩阵，使用size(0)取出该批的大小               correct += (predict == target).sum().item() # predict和target均为(batch_size,1)的矩阵，sum()求出相等的个数           print("准确率为：%.2f" % (correct / total))      # 自定义手写数字识别测试   def test_mydata():       image = Image.open('./test/test_one.png') # 读取自定义手写图片       image = image.resize((28,28)) # 裁剪尺寸为28*28       image = image.convert('L') # 转换为灰度图像       transform = transforms.ToTensor()       image = transform(image)       image = image.resize(1,1,28,28)       output = model(image)       probability,predict=torch.max(output.data,dim=1)       print("此手写图片值为:%d,其最大概率为:%.2f" % (predict[0],probability))       plt.title('此手写图片值为：{}'.format((int(predict))),fontname="SimHei")       plt.imshow(image.squeeze())       plt.show()      # 主函数   if __name__ == '__main__':       # 自定义测试       test_mydata()       # 训练与测试       # for i in range(5): # 训练和测试进行两轮       #     train()       #     test() |
| :--- |


代码参考：[https://blog.csdn.net/IronmanJay/article/details/128434368?spm=1001.2014.3001.5501](https://blog.csdn.net/IronmanJay/article/details/128434368?spm=1001.2014.3001.5501)

**参考文献**

[1]:LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86(11): 2278-2324.

[2]:Gao L, Chen P Y, Yu S. Demonstration of convolution kernel operation on resistive cross-point array[J].IEEE Electron Device Letters, 2016, 37(7): 870-873.

[3]: Gu J, Wang Z, Kuen J, et al. Recent advances in convolutional neural networks[J]. Pattern recognition, 2018, 77: 354-377.

[4]:Boureau Y L, Le Roux N, Bach F, et al. Ask the locals: multi-way local pooling for image recognition[C]//2011 international conference on computer vision. IEEE, 2011: 2651-2658.

[5]:Zeiler M D, Fergus R. Stochastic pooling for regularization of deep convolutional neural networks[J]. arXiv preprint arXiv:1301.3557, 2013.

[6]:Tara N. Sainath, Abdel-rahman Mohamed, Brian Kingsbury, et al.  Deep convolutional neural networks for LVCSR//Proceedings of the  IEEE International Conference on Acoustics, Speech and Signal  Processing, Vancouver, Canada, 2013: 8614-8618  

[7]:O'shea K, Nash R. An introduction to convolutional neural networks[J]. arXiv preprint arXiv:1511.08458, 2015.

