**3.2 Transformer 结构**

**前言：**

Transformers 是机器学习领域的一个新发展，最近引起了很多关注。它们在跟踪上下文方面表现非常出色，这也是它们生成的文本能够通顺的原因。我们将介绍它们的架构及其工作原理。希望能让大家了解到最最基础的Transformer架构。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130272148-97a538c7-f4dc-477a-b1ce-994554c7b06c.jpeg)

Transformer 模型是稳定的大模型架构之。它在论文《Attention is All You Need》中被引入。Transformers 可以用于写故事、作文、诗歌、回答问题、翻译语言、与人聊天，但它们究竟是什么？你会高兴地知道，Transformer 模型的架构并不复杂，它只是一些非常有用的组件的简单组合，每个组件都有其各自的功能。我将和你讲解所有这些组件。

简而言之，Transformer 是做什么的呢？想象一下，你在手机上写短信。每输入一个词，你可能会得到三个建议词。例如，如果你输入“Hello, how are”，手机可能会建议“you”或“your”作为下一个词。当然，如果你一直选择手机建议的词，你会很快发现这些词形成的信息没有意义。虽然每组3或4个连续的词可能有意义，但这些词并不能连成有意义的内容。这是因为手机中使用的模型并没有保持信息的整体上下文，它只是预测最后几个词后更可能出现的词。而 Transformers 则能包含正在写的内容的上下文，这就是Transformer如何生成有意义的文本的过程。

那么 transformers 是怎样进行训练的呢？它们是凭借海量的数据加以训练的，实际上涵盖了互联网中的所有数据。故而当您在 transformer 中输入“Hello, how are”这一语句时，它仅仅是依据互联网上的所有文本知晓，最为适宜的下一个词乃是“you”。倘若您给予它一个更为繁杂的指令，比方说“写一个故事”，它或许会觉得一个良好的起始词为“Once”。接着它会将这个词添加至指令当中，并认定下一个适宜的词为“upon”，依此类推。就如此逐词推进，直至创作出一个完整的故事。 

下文讲从以下几方面来讲解Transformer的架构。

Tokenization

Embedding

Positional encoding

Transformer block (several of these)

**Tokenization：**

分词是最基本的步骤。它包含一个大型的标记数据集，包括所有单词、标点符号等。分词步骤会处理每个单词、前缀、后缀和标点符号，并将它们映射到词库中已知的标记。对于分词器也有很多不同的，类似BPE，Tiktoken。更细致的知识请去专门了解。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130272492-962b3911-8bd1-49c2-a19f-bcaf7ad1f0d3.jpeg)

**Embedding**

一旦你完成了Tokenizer的工作，接下来就是将Tokenizer分好的词转换成模型可以处理的数字数字。为此，我们使用Embedding。对于词嵌入，简单来说：如果两个文本片段相似，那么它们对应向量中的数字也会相似（按分量来看，即每对相同位置的数字都相似）。反之，如果两个文本片段不同，那么它们对应向量中的数字也会不同。

我们以一个更抽象的视角来看这件事情，如果我们还是一样的一句话[Write, A, story, .]。这个List在python层的size是4。当我们Embedding它的时候，它会变成一个(4, embedding_size)的2D Tensor。每个Tokenizer分出的词我们都会用一个高纬向量来表示它。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130272678-a84fec88-7dec-46f3-87be-f1f2d5f97c6c.jpeg)

**Position encoding**

一旦我们获得了句子中每个标记对应的向量，下一步就是将所有这些向量合并成一个向量进行处理。将多个向量合并成一个向量最常见的方法是按分量相加。这意味着我们分别加每个坐标。

例如，如果有两个长度为2的向量[1,2]和[3,4]，它们相加的结果是[1+3, 2+4]，即[4, 6]。这种方法可行，但有一个小问题。加法具有交换性，意味着如果你以不同顺序加相同的数字，结果是一样的。在这种情况下，"I'm not sad, I'm happy"和"I'm not happy, I'm sad"这两个句子会得到相同的向量，因为它们包含相同的单词，只是顺序不同。这显然不好。

因此，我们必须想出一种方法，为这两个句子生成不同的向量。有几种方法可以解决这个问题，我们将使用其中一种：位置编码。位置编码包括将一系列预定义的向量添加到单词的嵌入向量中。这确保了每个句子都会得到一个独特的向量，而且包含相同单词但顺序不同的句子会被分配不同的向量。在下面的例子中，对应于"Write"、"a"、"story"和"."的向量变成了包含它们位置信息的修改后的向量，标记为"Write (1)"、"a (2)"、"story (3)"和". (4)"。

所以位置编码的本质是为了给天然无序的Transformer里加上顺序限制。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130272969-21c98df6-6fec-4ef2-ad4a-97ca5322bcd6.jpeg)

**Transformer block**

我们回顾一下目前的流程。首先，单词输入并被转换为标记（分词），然后标记化的单词被转换为数字（嵌入），接着考虑单词的顺序（位置编码）。这为我们输入模型的每个标记提供了一个向量。现在，下一步是预测这个句子中的下一个单词。这是通过一个非常大的神经网络来完成的，该网络被精确地训练来预测句子中的下一个单词。

论文《Attention is All you Need》中引入的注意力机制是 Transformer 模型的关键成分之一，也是它们效果如此之好的原因之一。

注意力组件被添加到前馈网络的每个块中。因此，如果你想象一个由几个较小神经网络块组成的大型前馈神经网络，其目标是预测下一个单词，那么每个块都会添加一个注意力组件。Transformer 的每个组件，称为 Transformer 块，主要由两个部分组成： 

Attention

前馈组件

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130273181-390f00ea-aca5-41c8-b090-56a3a85aa883.jpeg)

**Attention**

下一步是注意力机制。注意力机制解决了一个非常重要的问题：上下文问题。有时候，你知道，同一个词可能有不同的含义。这往往会让语言模型感到困惑，因为嵌入仅仅是将单词转换为向量，而不知道它们使用的是哪个词义。

注意力是一种非常有用的技术，可以帮助语言模型理解上下文。为了理解注意力是如何工作的，考虑以下两个句子：

句子1：河岸（The bank of the river）。

句子2：银行里的钱（Money in the bank）。

如你所见，"bank"这个词在两句中都出现了，但有不同的含义。在句子1中，我们指的是河边的陆地，而在句子2中指的是银行。计算机并不知道这一点，所以我们需要以某种方式将这种知识注入其中。什么可以帮助我们呢？看起来句子中的其他词可以帮上忙。

对于第一个句子，"the"和"of"这些词并没有帮助。但是"river"这个词让我们知道我们在谈论河边的陆地。同样，在句子2中，"money"这个词帮助我们理解"bank"现在指的是存放钱的机构。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130273406-d7e666f0-7175-4b02-a2bc-5635ad8fc526.jpeg)

这就是一个attention的流程，通过几个矩阵乘法和softmax操作。来得到了最后的输出。

**MLP**

多层感知器(MLP)在大型语言模型(LLM)中扮演着关键角色，它是Transformer架构中不可或缺的组成部分。作为前馈网络组件，MLP通常位于自注意力层之后，通过其两层全连接结构和非线性激活函数，有效地增强了模型的非线性表达能力。

MLP处理和转换自注意力层的输出，并帮助模型学习更复杂的模式和关系，从而提升整体性能。其较宽的中间层设计进一步增强了模型的表达能力，而高度可并行化的特性则确保了大规模模型训练和推理的计算效率。

MLP 层比较简单，是一个两层的全连接层，第一层的激活函数为 Relu，第二层不使用激活函数，对应的公式如下。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/1805392/1729130273743-facec2d3-34f6-4af1-ae08-74fb8ba2ef66.jpeg)

**总结**

到这里Transformer的架构就介绍完毕了，这里我们并没有进行实操。而是以图例的形式让大家尽可能了解到Transformer中的结构。

